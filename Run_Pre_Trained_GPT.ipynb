{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Run Pre-Trained GPT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19ft5ldGPWjL"
      },
      "source": [
        "# Load the pre-trained model and generate text, measuring its perplexity\n",
        "\n",
        "## Pieces of code were borrowed from the following public repositories and tutorials:\n",
        "### https://mccormickml.com/2019/07/22/BERT-fine-tuning/\n",
        "### https://snappishproductions.com/blog/2020/03/01/chapter-9-text-generation-with-gpt-2-and-only-pytorch.html.html\n",
        "### Hugging Face Language model fine-tuning script https://huggingface.co/transformers/v2.0.0/examples.html#language-model-fine-tuning\n",
        "### Rey Farhan: Easy GPT2 fine-tuning with Hugging Face and PyTorch https://colab.research.google.com/drive/13dZVYEOMhXhkXWfvSMVM1TTtUDrT6Aeh?usp=sharing#scrollTo=EKOTlwcmxmej\n",
        "### Code for measuring perplexity is based on https://huggingface.co/transformers/perplexity.html and taken from https://github.com/huggingface/transformers/issues/4147"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3C0184vGvIxj",
        "outputId": "53a3f5d3-bdb1-4197-a437-19ba0d600f85"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 37.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 51.1 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 65.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJqPMqXjwK0p"
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
        "import time\n",
        "import datetime\n",
        "from google.colab import drive\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
        "torch.manual_seed(42)\n",
        "\n",
        "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxPLfb7ry6Li",
        "outputId": "df6e19c8-c0fa-4c3e-aff1-db2244a4858b"
      },
      "source": [
        "# mount my Google Drive directory and access the training data located there\n",
        "gdrive_dir = '/content/drive/'\n",
        "data_dir = os.path.join(gdrive_dir, \"'My Drive'\",\"'Colab Notebooks'\")\n",
        "\n",
        "drive.mount(gdrive_dir, force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zpXin9OUZv9",
        "outputId": "2f09cfab-aeb3-4c90-b8be-dc4c7f21efab"
      },
      "source": [
        "cd '/content/drive/MyDrive/Colab Notebooks/model_save'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/model_save\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-_EegXOVLsd",
        "outputId": "efea0111-a617-400d-cfa8-0b8527f32ef2"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/Colab Notebooks/model_save\")\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "added_tokens.json  merges.txt\t      special_tokens_map.json  vocab.json\n",
            "config.json\t   pytorch_model.bin  tokenizer_config.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7_PDwRWwa9I"
      },
      "source": [
        "# Tell pytorch to run this model on the GPU.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2wJM9kSRpep",
        "outputId": "7ef9ead6-6895-4a62-b9c2-1f266fd4f2e3"
      },
      "source": [
        "!ls -l --block-size=K \"/content/drive/MyDrive/Colab Notebooks/model_save\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 499775K\n",
            "-rw------- 1 root root      1K Jul  6 06:47 added_tokens.json\n",
            "-rw------- 1 root root      1K Jul  6 06:47 config.json\n",
            "-rw------- 1 root root    446K Jul  6 06:47 merges.txt\n",
            "-rw------- 1 root root 498448K Jul  6 06:47 pytorch_model.bin\n",
            "-rw------- 1 root root      1K Jul  6 06:47 special_tokens_map.json\n",
            "-rw------- 1 root root      1K Jul  6 06:47 tokenizer_config.json\n",
            "-rw------- 1 root root    878K Jul  6 06:47 vocab.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpVptlPQQopR",
        "outputId": "37a070b7-ddf2-4078-976c-611512362055"
      },
      "source": [
        "\n",
        "!ls -l --block-size=M \"/content/drive/MyDrive/Colab Notebooks/model_save/pytorch_model.bin\"\n",
        "\n",
        "# Copy the model files to a directory in your Google Drive.\n",
        "#!cp -r '/content/drive/MyDrive/Colab Notebooks/model_save' $data_dir\n",
        "output_dir = '/content/drive/MyDrive/Colab Notebooks/model_save'\n",
        "# # Load a trained model and vocabulary that you have fine-tuned\n",
        "model = GPT2LMHeadModel.from_pretrained(output_dir)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(output_dir)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw------- 1 root root 487M Jul  6 06:47 '/content/drive/MyDrive/Colab Notebooks/model_save/pytorch_model.bin'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50259, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50259, bias=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5DyZ3OeWOcm",
        "outputId": "133fd9c6-e039-4123-85fc-437dc586403b"
      },
      "source": [
        "model.eval()\n",
        "sentence = 'CSS Dimensions'\n",
        "input_ids = tokenizer.encode(sentence, return_tensors='pt')\n",
        "#greedy output\n",
        "#output= model.generate(input_ids, max_length=1024)\n",
        "#best-possible output achieved by adding more parameters\n",
        "output = model.generate(input_ids, min_length=1024, max_length=1024, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95, early_stopping=True).to('cpu')\n",
        "# average result param\n",
        "#output = model.generate(input_ids, do_sample=True, max_length=50, top_p=0.92, top_k=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
            "  return torch.floor_divide(self, other)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQHBSzUtXahA",
        "outputId": "00c9105b-1445-4add-d7bb-a8d1e2f67bb4"
      },
      "source": [
        "output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[49155, 41265,   389,  ...,   340, 12229,   663]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpvRYmXlXoBR",
        "outputId": "b5d41b52-250d-48ee-90e2-84ae1c5a2803"
      },
      "source": [
        "print(tokenizer.decode(output[0], skip_special_tokens=True))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CSS Dimensions are measured in pixels by using the square root of the x- and y-axis.,The, property specifies the first browser version that fully supports the \r\n",
            ", property.,For a complete list of all available HTML tags, visit our,.,Get certified,by completing,a course today! Exercises in,tuition,tuples, and Matplotlib are now 100% complete and you don't need a registration to use them!,Good luck!,If you have any +/- comments or questions, kindly feel free to send me an e-mail at,gives me a small percentage (at no extra cost to you) and I will try to answer them in a nice and open-ended manner.,I'm currently working as a Software Engineer at Joyent, which means I'm actively involved in the development and testing of HTML, CSS, XHTML, jQuery, Bootstrap, Webpack, VB Scripting, angular and angular-components. I do my best to keep my time and motivation to myself, so if you find me useful, I would be greatly appreciated and look forward to reading your comments and contributions to the rest of my projects.,You can download a printable version of this manual by going to:,, and selecting \"Open Source\" from the drop-down menu.,A complete reference manual for all major browsers and their related technologies is available at:,,, or,:,A glossary of terms and usage is also available on the World Wide Web Consortium (W3C).,The Mozilla Corporation (Mountain 21) is the world’s largest personal-computer software company, with offices in Tokyo,Tokyo,Shigeru and Macromedia. Mozilla is a Distinguished Research Organization (DO) founded in 1994 by Sun Microsystems, a division of General Motors Corporation.,Software is copyrighted and its source code is under the GNU General Public License (GPL), version 3.0.,To obtain a copy of a work, you must, first, go to W3Schools.,Then you can request that the work be turned over to a non-XHTML-compliant Web site (such as Hypertext Transfer Protocol (HTTP) for Unix-like operating systems), such as Netscape Navigator, Firefox, Safari, or Internet Explorer.,Once that request is received, it is sent back to Mozilla, who then revokes the request if it does not comply with its terms of use.,In the event that you do not want to turn over your work to an X-Perl-enabled Web Server (Xperl), then you will have to download and install the X Window MFC operating system (xmfcmc) on your system. Once that installation is complete, the next step is to create a user interface for the user to interact with the application.,Navigate your mouse over the \"About Us\" section and select \"Web Server 2008 R2\".,Now, open the Terminal window and type \"demofile\" into the text box. Type the following code to start up a web server that will listen on TCP/IP and listen for requests from all your web pages:,Now that we have established a connection, we can start next chapter of our tutorial with a simple Hello World program. Start by creating a file called hello.py and user will see this file when he/she visits our website:,This hello file is located at /var/www/html/index.htm and it will display a welcome message stating \"Hello World!\" and a brief description of what we are about to do:,You will learn a lot about web design in this tutorial, but for now let's concentrate on basic HTML and CSS. We will start by defining a basic set of attributes for each HTML element. These attributes will be used to define the look and feel of each element, while also defining the relationships between the elements. The following table lists all the attributes we will use in our HTML document −, − The, attribute defines the width and height of an element., − This attribute specifies how many pixels the element should be displayed. It can be one of two values, one for absolute or relative width or height.,This attribute can also have one or more values for relative or absolute width, depending on how much space is left between them. For example, if the height is 50% of its original value, then the browser window will scroll down to see the content of <div> and <h1> instead of scrolling up and down. This will produce the same result as scrolling down and up. You can read more about these attributes at the, chapter.,Here is an example of how to set different widths and heights for different screen sizes:,Here are some examples to show you the difference between horizontal and vertical scroll bars:, − A horizontal scrollbar is one that is displayed horizontally on a page and vertically on an HTML page. If the page has a width of 100%, the scroll bar will gradually increase in width until it reaches its\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_yy-KM7RW7y"
      },
      "source": [
        "# Perplexity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx1d22-8ZlB7"
      },
      "source": [
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKCNAexCRWlW"
      },
      "source": [
        " def calculatePerplexity(sentence,model,tokenizer):\n",
        "        input_ids = torch.tensor(tokenizer.encode(sentence)).unsqueeze(0) \n",
        "        input_ids = input_ids.to('cpu')\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids, labels=input_ids)\n",
        "        loss, logits = outputs[:2]\n",
        "        return math.exp(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eFcR6CYZc7B",
        "outputId": "e22af51e-44c5-47cc-b08f-218185a9cf86"
      },
      "source": [
        "print(calculatePerplexity(sentence, model, tokenizer))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11914676.948942969\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}